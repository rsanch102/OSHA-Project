filter(Date == today) %>%
distinct()
#flip
race_new_cases <- gather(x, key = "Race", value = "New_Cases", New_Cases_African_American, New_Cases_Asian, New_Cases_Hispanic, New_Cases_Multi_Racial, New_Cases_Native_American, New_Cases_Other, New_Cases_Race_Or_Ethnicity_Unknown, New_Cases_White)
write.csv(race_new_cases, file = "Demographics/race_new_cases.csv")
race_new_cases
race_main_file_spanish <- race_main_file %>%
rename(Fecha=Date, Casos_Afroamericano = Cases_African_American,
Casos_Blanco = Cases_White,
Casos_Asiático = Cases_Asian,
Casos_Nativo_Americano = Cases_Native_American,
Casos_Oriundo_de_las_Islas_del_Océano_Pacífico = Cases_Pacific_Islander,
Casos_Multirracial = Cases_Multi_Racial,
Casos_Hispano = Cases_Hispanic,
Muertes_Afroamericanos = Deaths_African_American,
Muertes_Blanco = Deaths_White,
Muertes_Asiático = Deaths_Asian,
Muertes_Nativo_Americano = Deaths_Native_American,
Muertes_Oriundo_de_las_Islas_del_Océano_Pacífico = Deaths_Pacific_Islander,
Muertes_Multirracial = Deaths_Multi_Racial,
Muertes_Hispano = Deaths_Hispanic,
Nuevos_Casos_Afroamericano = New_Cases_African_American,
Nuevos_Casos_Blanco = New_Cases_White,
Nuevos_Casos_Asiático = New_Cases_Asian,
Nuevos_Casos_Nativo_Americano = New_Cases_Native_American,
Nuevos_Casos_Oriundo_de_las_Islas_del_Océano_Pacífico = New_Cases_Pacific_Islander,
Nuevos_Casos_Multirracial = New_Cases_Multi_Racial,
Nuevos_Casos_Hispano = New_Cases_Hispanic,
Nuevas_Muertes_Afroamericano = New_Deaths_African_American,
Nuevas_Muertes_Blanco = New_Deaths_White,
Nuevas_Muertes_Asiático = New_Deaths_Asian,
Nuevas_Muertes_Nativo_Americano = New_Deaths_Native_American,
Nuevas_Muertes_Oriundo_de_las_Islas_del_Océano_Pacífico = New_Deaths_Pacific_Islander,
Nuevas_Muertes_Multirracial = New_Deaths_Multi_Racial,
Nuevas_Muertes_Hispano = New_Deaths_Hispanic,
Casos_por_cada_10k_Afroamericano = Cases_Per_10_000_African_American,
Casos_por_cada_10k_Blanco = Cases_Per_10_000_White,
Casos__por_cada_10k_Asiático = Cases_Per_10_000_Asian,
Casos_por_cada_10k_Nativo_Americano = Cases_Per_10_000_Native_American,
Casos_por_cada_10k_Oriundo_de_las_Islas_del_Océano_Pacífico = Cases_Per_10_000_Pacific_Islander,
Casos_por_cada_10k_Multirracial = Cases_Per_10_000_Multi_Racial,
Casos_por_cada_10k_Hispano = Cases_Per_10_000_Hispanic,
Muertes_por_cada_10k_Afroamericanos = Deaths_Per_10_000_African_American,
Muertes_por_cada_10k_Blanco = Deaths_Per_10_000_White,
Muertes_por_cada_10k_Asiático = Deaths_Per_10_000_Asian,
Muertes_por_cada_10k_Nativo_Americano = Deaths_Per_10_000_Native_American,
Muertes_por_cada_10k_Oriundo_de_las_Islas_del_Océano_Pacífico = Deaths_Per_10_000_Pacific_Islander,
Muertes_por_cada_10k_Multirracial = Deaths_Per_10_000_Multi_Racial,
Muertes_por_cada_10k_Hispano = Deaths_Per_10_000_Hispanic)
race_main_file_spanish
write.csv(race_main_file_spanish, file = "SpanishData/race_main_file_spanish.csv")
x <- race_main_file_spanish %>%
select(Fecha, Nuevos_Casos_Afroamericano, Nuevos_Casos_Asiático, Nuevos_Casos_Hispano, Nuevos_Casos_Multirracial, Nuevos_Casos_Nativo_Americano, Nuevos_Casos_Blanco) %>%
filter(Fecha == today) %>%
distinct()
#flip
race_new_cases_spanish <- gather(x, key = "Razo o Ethnicidad", value = "Nuevos_Casos", Nuevos_Casos_Afroamericano, Nuevos_Casos_Asiático, Nuevos_Casos_Hispano, Nuevos_Casos_Multirracial, Nuevos_Casos_Nativo_Americano, Nuevos_Casos_Blanco)
write.csv(race_new_cases_spanish, file = "SpanishData/race_new_cases_spanish.csv")
race_new_cases_spanish
race_new_deaths <- race_main_file %>%
select(Date, New_Deaths_African_American, New_Deaths_Asian, New_Deaths_Hispanic, New_Deaths_Multi_Racial, New_Deaths_Native_American, New_Deaths_Other, New_Deaths_Race_Or_Ethnicity_Unknown, New_Deaths_White) %>%
filter(Date == today) %>%
distinct()
#flip
race_new_deaths <- gather(race_new_deaths, key = "Race", value = "New_Deaths", New_Deaths_African_American, New_Deaths_Asian, New_Deaths_Hispanic, New_Deaths_Multi_Racial, New_Deaths_Native_American, New_Deaths_Other, New_Deaths_Race_Or_Ethnicity_Unknown, New_Deaths_White)
race_new_deaths
write.csv(race_new_deaths, file = "Demographics/race_new_deaths.csv")
race_new_deaths_spanish <- race_main_file_spanish %>%
select(Fecha, Nuevas_Muertes_Afroamericano, Nuevas_Muertes_Asiático, Nuevas_Muertes_Hispano, Nuevas_Muertes_Multirracial, Nuevas_Muertes_Nativo_Americano, Nuevas_Muertes_Blanco) %>%
filter(Fecha == today) %>%
distinct()
#flip
race_new_deaths_spanish <- gather(race_new_deaths_spanish, key = "Razo o Ethnicidad", value = "Nuevas_Muertes", Nuevas_Muertes_Afroamericano, Nuevas_Muertes_Asiático, Nuevas_Muertes_Hispano, Nuevas_Muertes_Multirracial, Nuevas_Muertes_Nativo_Americano, Nuevas_Muertes_Blanco)
write.csv(race_new_deaths_spanish, file = "SpanishData/race_new_deaths.csv")
race_new_deaths_spanish
head(race_new_cases)
#SF$disposition1 <- str_replace_all(SF$disposition1, pattern=fixed('ABA'), replacement=fixed('Abated') )
#strip the race name down
race_new_cases$NEW <- str_replace_all(race_new_cases$Race, pattern=fixed('New_Cases_'), replacement=fixed(''))
race_new_deaths$NEW <- str_replace_all(race_new_deaths$Race, pattern=fixed('New_Deaths_'), replacement=fixed(''))
race_new_cases_deaths <- race_new_cases %>%
inner_join(race_new_deaths, by=c("NEW", "Date"))
race_new_cases_deaths <- race_new_cases_deaths %>%
select(Date, NEW, New_Cases, New_Deaths)
colnames(race_new_cases_deaths)[2] <- "Race_Ethnicity"
write.csv(race_new_cases_deaths, file = "Demographics/race_new_cases_deaths.csv")
head(race_new_cases_deaths)
#Spanish translation
#Spanish translation
race_new_cases_deaths_spanish <- race_new_cases_deaths %>%
rename(Nuevas_Muertes = New_Deaths, Fecha = Date, Nuevos_Casos = New_Cases, Razo_o_Ethnicidad=Race_Ethnicity)
race_new_cases_deaths_spanish$ Razo_o_Ethnicidad <- str_replace_all(race_new_cases_deaths_spanish$ Razo_o_Ethnicidad, pattern=fixed('African_American'), replacement=fixed('Afroamericano') )
race_new_cases_deaths_spanish$ Razo_o_Ethnicidad <- str_replace_all(race_new_cases_deaths_spanish$ Razo_o_Ethnicidad, pattern=fixed('Asian'), replacement=fixed('Asiático') )
race_new_cases_deaths_spanish$ Razo_o_Ethnicidad <- str_replace_all(race_new_cases_deaths_spanish$ Razo_o_Ethnicidad, pattern=fixed('Hispanic'), replacement=fixed('Hispano') )
race_new_cases_deaths_spanish$ Razo_o_Ethnicidad <- str_replace_all(race_new_cases_deaths_spanish$ Razo_o_Ethnicidad, pattern=fixed('Multi_Racial'), replacement=fixed('Multirracial') )
race_new_cases_deaths_spanish$ Razo_o_Ethnicidad <- str_replace_all(race_new_cases_deaths_spanish$ Razo_o_Ethnicidad, pattern=fixed('Native_American'), replacement=fixed('Nativo_Americano') )
race_new_cases_deaths_spanish$ Razo_o_Ethnicidad <- str_replace_all(race_new_cases_deaths_spanish$ Razo_o_Ethnicidad, pattern=fixed('Pacific_Islander'), replacement=fixed('de_las_Islas_del_Océano_Pacífico') )
race_new_cases_deaths_spanish$ Razo_o_Ethnicidad <- str_replace_all(race_new_cases_deaths_spanish$ Razo_o_Ethnicidad, pattern=fixed('Other'), replacement=fixed('Otro') )
race_new_cases_deaths_spanish$ Razo_o_Ethnicidad <- str_replace_all(race_new_cases_deaths_spanish$ Razo_o_Ethnicidad, pattern=fixed('White'), replacement=fixed('Blanco') )
race_new_cases_deaths_spanish
write.csv(race_new_cases_deaths_spanish, file = "SpanishData/race_new_cases_deaths_spanish.csv")
today_gender <- today_demo %>%
select(Date, Male, Female, Unk_Gender)
today_gender2 <- today_gender
today_gender2 <- today_gender2 %>%
rename(Cases_Male = Male, Cases_Female = Female, Cases_Gender_Unknown = Unk_Gender)
today_gender2$Date <- as.Date(today_gender2$Date)
#today_gender2 <- janitor::clean_names(today_gender2)
glimpse(today_gender2)
#gender_master <- rio::import("gender_master.csv")
gender_master <- rio::import("https://raw.githubusercontent.com/Arkansascovid/Main/master/MasterData/gender_master.csv")
gender_master$Date <- lubridate::ymd(gender_master$Date)
head(gender_master)
yesterday_gender <- gender_master %>%
filter(Date == yesterday)
yesterday_gender <- gender_master %>%
select(Date, Cases_Male, Cases_Female, Cases_Gender_Unknown)
glimpse(yesterday_gender)
twodays3 <- smartbind(today_gender2, yesterday_gender)
twodays3$Date <- as.Date(twodays3$Date)
# twodays3 <- twodays3 %>%
#   distinct()
#cut an extra day off
#twodays3 <- slice(twodays3, -c(1))
glimpse(twodays3)
gender2 <- twodays3 %>%
mutate(New_Cases_Male = (Cases_Male -lead(Cases_Male))) %>%
mutate(New_Cases_Female = (Cases_Female-lead(Cases_Female))) %>%
mutate(New_Cases_Gender_Unknown = (Cases_Gender_Unknown-lead(Cases_Gender_Unknown)))
#cut first row if needed for cleaning
#gender2 <- slice(gender2, -c(1))
head(gender2)
write.csv(gender2, file = "Demographics/gender_master.csv")
write.csv(gender2, file = "MasterData/gender_master.csv")
write.csv(gender2, file = "Demographics/gender_FLOURISH_master.csv")
gender_new_cases <- gender2 %>%
select(Date, "New_Cases_Male", "New_Cases_Female","New_Cases_Gender_Unknown") %>%
filter(Date == today)
#flip
gender_new_cases <- gather(gender_new_cases, key = "Gender", value = "New_Cases", "New_Cases_Male", "New_Cases_Female","New_Cases_Gender_Unknown")
gender_new_cases
write.csv(gender_new_cases, file = "Demographics/gender_new_cases.csv")
#Spanish Translation
# write.csv(gender_new_cases_spanish, file = "SpanishData/gender_new_cases_spanish.csv")
# gender_new_cases_spanish
gender_spanish_master <- gender2 %>%
rename(Fecha = Date, Casos_Hombres = Cases_Male, Casos_Mujeres = Cases_Female, Casos_Género_Desconocidos = Cases_Gender_Unknown, Nuevos_Casos_Hombres = New_Cases_Male, Nuevos_Casos_Mujeres = New_Cases_Female, Nuevos_Casos_Género_Desconocidos = New_Cases_Gender_Unknown)
write.csv(gender_spanish_master, file = "SpanishData/gender_FLOURISH_master_spanish.csv")
gender_new_cases_spanish <- gender_spanish_master %>%
select(Fecha, "Nuevos_Casos_Hombres", "Nuevos_Casos_Mujeres","Nuevos_Casos_Género_Desconocidos") %>%
filter(Fecha == today)
#flip
gender_new_cases_spanish <- gather(gender_new_cases_spanish, key = "Género", value = "Nuevos_Casos", "Nuevos_Casos_Hombres", "Nuevos_Casos_Mujeres","Nuevos_Casos_Género_Desconocidos")
write.csv(gender_new_cases_spanish, file = "SpanishData/gender_new_cases_spanish.csv")
gender_new_cases_spanish
#install.packages("tidyverse",dependencies = TRUE)
#install.packages("slider")
#install.packages("zoo")
#install.packages("gtools")
#install.packages("kableExtra")
#install.packages("formattable")
#install.packages("janitor")
#install.packages("reshape2")
library(tidyverse)
library(janitor)
library(lubridate)
library(jsonlite)
library(gtools)
library(zoo)
library(reshape2)
library(slider)
library(formattable)
#New County json feed
#38 Variables
q <- fromJSON('https://services.arcgis.com/PwY9ZuZRDiI5nXUB/ArcGIS/rest/services/UPDATED_ADH_COVID19_HEALTH_REGION_METRICS/FeatureServer/0/query?where=0%3D0&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&returnGeodetic=false&outFields=*&returnGeometry=true&returnCentroid=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pjson&token=')
#OnVents and PositiveAdmits represent the same data in the daily Tweet slide for vents and total hospitalized
hospital_new <- q[["features"]][["attributes"]]
hospital_new$Date <- Sys.Date()
#makes a spreadsheet
#write.csv(hospital, "hospital_ADH_API.csv")
#check math against the hospital tweet slide
sum(hospital_new$PositiveAdmits)
sum(hospital_new$OnVents)
#today's date
today <- Sys.Date()
#NOTE: IF YOU ARE RUNNING THIS A DAY LATE, USE THIS CODE TO WORK PROPERLY
#today <- Sys.Date()-1
#today_county$mydate <-"2020-09-22- THE OLD DATE...."
#yesterday's date
yesterday <- (today-1)
#Calculate statewide totals
hospital_new <- hospital_new %>%
janitor::adorn_totals("row")
hospital_new <- as.data.frame(hospital_new)
glimpse(hospital_new)
hospital_today <- hospital_new %>%
filter(OBJECTID =="Total")
hospital_today$date <- today
hospital_today <- hospital_today %>%
rename('Hospitalized'= PositiveAdmits, 'Vent'= OnVents)
hospital_today <- hospital_today %>%
select(date, Hospitalized, Vent)
hospital_master <- rio::import("https://raw.githubusercontent.com/Arkansascovid/Main/master/MasterData/hospital_master.csv")
hospital_master <- hospital_master %>%
select(date, Hospitalized, Vent, Hosp_Change_from_Yesterday, Pct_Vent, Pct_Hospitalized, active_cases, confirmed_active)
#roll back a date
# hospital_master <- hospital_master %>%
#     filter(date<=("2021-05-30"))
#Join new to old
hospital_master <- smartbind(hospital_today, hospital_master)
hospital_master$date <- as.Date(hospital_master$date)
glimpse(hospital_master)
main_hospital <- master2 %>%
filter(county_nam=="Arkansas_all_counties") %>%
select(mydate, confirmed_active, active_cases) %>%
rename('date' = mydate)
# #If needed Roll back a day
#  main_hospital <- main_hospital %>%
#     filter(date<=("2021-05-31"))
hospital2 <- hospital_master %>%
select(date, Hospitalized, Vent)
main_hospital2 <- inner_join(main_hospital, hospital2, by=c("date"="date"))
# main_hospital3 <- main_hospital2 %>%
#   mutate(Vent_Change_from_Yesterday = (Vent-lead(Vent)))
# main_hospital2 <- inner_join(main_hospital, hospital_master, by=c("date"="date", "active_cases"="active_cases", "confirmed_active"="confirmed_active"))
# glimpse(main_hospital)
# glimpse(hospital_master)
glimpse(main_hospital2)
hospital1 <- main_hospital2 %>%
mutate(Hosp_Change_from_Yesterday = (Hospitalized-lead(Hospitalized))) %>%
#mutate(Vent_Change_from_Yesterday = (Vent-lead(Vent))) %>%
mutate(Pct_Vent = (Vent/Hospitalized)*100) %>%
mutate(Pct_Hospitalized = (Hospitalized/active_cases)*100)
# hospital1 <- hospital1 %>%
#   filter(date ==(today))
# hospital1 <- hospital1 %>%
#   filter(date >=("2021-05-17"))
hospital1 <- hospital1 %>%
filter(date >(yesterday))
#Cut rows from df
#hospital1 <- slice(hospital1, -c(1))
hospital1$Pct_Vent <- round(hospital1$Pct_Vent, 2)
hospital1$Pct_Hospitalized <- round(hospital1$Pct_Hospitalized, 2)
hospital1
#make hospital_master.csv
hospital_master <- hospital_master %>%
filter(date <= yesterday)
hospital_master <- rbind(hospital1, hospital_master)
hospital_master <- hospital_master %>%
arrange(desc(date)) %>%
distinct()
#edit out rows if needed
#hospital_master <- slice(hospital_master, -c(2))
head(hospital_master)
glimpse(hospital_master)
write.csv(hospital_master, file = "MasterData/hospital_master.csv")
#Flourish - May 1, 2020 filter
hospital_FLOURISH <- hospital_master %>%
filter(date >= "2020-05-01")
#hospital_FLOURISH <- hospital_FLOURISH[ -c(1) ]
write.csv(hospital_FLOURISH, file = "HomePageData/hospital_FLOURISH.csv")
#cut extra column from hospital_master
#hospital_master <- hospital_master[ -c(1) ]
hospital2 <- hospital_master %>%
filter(date>=(yesterday)) %>%
select(date, Hospitalized, Vent, Hosp_Change_from_Yesterday)
hospital2 <- hospital2 %>%
rename(Date = date, On_Vents = Vent, Hospital_Change_from_Yesterday = Hosp_Change_from_Yesterday)
hh <- t(hospital2)
hh <- data.frame(Value = row.names(hh), hh)
colnames(hh)[1:3] <- c("Value","Today", "Yesterday")
row.names(hh) <- NULL
df5 <- melt(hospital2[,c("Date", "Hospitalized", "Hospital_Change_from_Yesterday", "On_Vents")], id.vars = 1)
df5 <- df5 %>%
rename(Detail = variable, Amount = value)
ggplot(df5,aes(x = Date, y = Amount, label = Amount, fill= Detail)) +
geom_bar(stat="identity", position="dodge", color="white")+
scale_fill_manual(values=c("#B3BF08", "#08B3BF", "#D68037"))+
scale_y_continuous(limits=c(0, 350))  +
theme_bw() +
theme(
plot.title = element_text(face = "bold", size = 16),
legend.background = element_rect(fill = "white", size = .01, colour = "white"),
legend.justification = c(0, 1),
#adjust the box position. First number horizontal, second, vertical
legend.position = c(.617, .96),
#legend.position = c(.617, .38),
#legend.position = c(.1, .38),
axis.ticks = element_line(colour = "grey70", size = 0.2),
panel.grid.major = element_line(colour = "grey70", size = 0.2),
panel.grid.minor = element_blank()
)+
geom_col(position = position_dodge2(width = 0.9, preserve = "single")) +
geom_text(position = position_dodge2(width = 0.9, preserve = "single"), vjust=-0.5, hjust=+0.5) +
labs(title = "COVID-19 Hospitalizations in Arkansas Announced Today",
subtitle = "ADH Data for June 1, 2021",
caption = "Graphic by ArkansasCovid.com",
y="Amount",
x="Date")
ggsave("Hospital.png",device = "png",width=9,height=6, dpi=400)
#cut extra column from hospital_master
#hospital_master <- hospital_master[ -c(1) ]
hospital2 <- hospital_master %>%
filter(date>=(yesterday)) %>%
select(date, Hospitalized, Vent, Hosp_Change_from_Yesterday)
hospital2 <- hospital2 %>%
rename(Date = date, On_Vents = Vent, Hospital_Change_from_Yesterday = Hosp_Change_from_Yesterday)
hh <- t(hospital2)
hh <- data.frame(Value = row.names(hh), hh)
colnames(hh)[1:3] <- c("Value","Today", "Yesterday")
row.names(hh) <- NULL
df5 <- melt(hospital2[,c("Date", "Hospitalized", "Hospital_Change_from_Yesterday", "On_Vents")], id.vars = 1)
df5 <- df5 %>%
rename(Detail = variable, Amount = value)
ggplot(df5,aes(x = Date, y = Amount, label = Amount, fill= Detail)) +
geom_bar(stat="identity", position="dodge", color="white")+
scale_fill_manual(values=c("#B3BF08", "#08B3BF", "#D68037"))+
scale_y_continuous(limits=c(0, 350))  +
theme_bw() +
theme(
plot.title = element_text(face = "bold", size = 16),
legend.background = element_rect(fill = "white", size = .01, colour = "white"),
legend.justification = c(0, 1),
#adjust the box position. First number horizontal, second, vertical
legend.position = c(.617, .96),
#legend.position = c(.617, .38),
#legend.position = c(.1, .38),
axis.ticks = element_line(colour = "grey70", size = 0.2),
panel.grid.major = element_line(colour = "grey70", size = 0.2),
panel.grid.minor = element_blank()
)+
geom_col(position = position_dodge2(width = 0.9, preserve = "single")) +
geom_text(position = position_dodge2(width = 0.9, preserve = "single"), vjust=-0.5, hjust=+0.5) +
labs(title = "COVID-19 Hospitalizations in Arkansas Announced Today",
subtitle = "ADH Data for June 6, 2021",
caption = "Graphic by ArkansasCovid.com",
y="Amount",
x="Date")
ggsave("Hospital.png",device = "png",width=9,height=6, dpi=400)
knitr::opts_chunk$set(echo = TRUE)
# For general data science work
library(tidyverse)
# For data cleaning
library(janitor)
# For writing data to google sheets
library(gargle)
library(googlesheets4)
#source("keys/keys.R")
# For fancy tables
# library(DT)
# library(kableExtra)
# # For producing html files
# library(knitr)
demo()
install.packages("quorto")
library(janitor)
install.packages(quorto)
install.packages("tidyverse")
install.packages("rio")
install.packages("janitor")
install.packages("tidyverse")
install.packages("tabulapdf", repos = c("https://ropensci.r-universe.dev", "https://cloud.r-project.org"))
# install.packages('janitor')
# install.packages('tidyverse')
library(tidyverse)
install.packages("tabulapdf", repos = c("https://ropensci.r-universe.dev", "https://cloud.r-project.org"))
install.packages("tidyverse")
knitr::opts_chunk$set(echo = TRUE)
#| output: false
install.packages("tidyverse")
# Run this block to load image
knitr::include_graphics(rep("assets/images/rvest1.png"))
#| output: false
install.packages("tidyverse")
install.packages("rvest")
install.packages("janitor")
library(rvest)
library(tidyverse)
#| output: false
install.packages("tidyverse")
install.packages("rvest")
install.packages("janitor")
library(rvest)
install.packages("rvest")
library(tidyverse)
setwd("~/Desktop/DJNF_Merrill/OSHA Project")
knitr::opts_chunk$set(echo = TRUE)
#I loaded two libraries into R, ###httr ### hot and rvest, to pull a http and scrape data from a webpage.
# Then I loaded the headers to bypass the ‘403’ authentication error when loading the osha.gov website. The header which was partially written by Sean, Austin, Chatgpt, and myself was to convince the website that I was not a bot, but a person submitting a request and looking for the data.
# By having the header defined, a 403 code no longer appeared, but a 304 request did. I then had to modify my header by changing the value of the cookie that the site was requesting, I just changed the value to equal ‘1’. Also I then defined the url with the OSHA query using two variables, State=Arkansas, Office=Little Rock, and I also was looking for Fed/State data, dating from 2024 back to the given search date of 2019.
install.packages("tidyverse")
#rsw comment: always load tidyverse
library(tidyverse)
update.packages()
knitr::opts_chunk$set(echo = TRUE)
install.packages("tidyverse")
library(httr)
library(rvest)
#rsw comment: always load tidyverse
library(tidyverse)
library(janitor)
install.packages("janitor")
library(janitor)
# Define the headers
headers <- c(
"Accept" = "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,/;q=0.8,application/signed-exchange;v=b3;q=0.7",
"Accept-Encoding" = "gzip, deflate, br, zstd",
"Accept-Language" = "en-US,en;q=0.9",
"Cache-Control" = "max-age=0",
"Cookie" = "_gid=1",
"If-Modified-Since" = "Mon, 03 Jun 2024 13:39:50 GMT",
"If-None-Match" = "\"1717421990\"",
"Priority" = "u=0, i",
"Sec-Ch-Ua" = "\"Google Chrome\";v=\"125\", \"Chromium\";v=\"125\", \"Not.A/Brand\";v=\"24\"",
"Sec-Ch-Ua-Mobile" = "?0",
"Sec-Ch-Ua-Platform" = "\"macOS\"",
"Sec-Fetch-Dest" = "document",
"Sec-Fetch-Mode" = "navigate",
"Sec-Fetch-Site" = "none",
"Sec-Fetch-User" = "?1",
"Upgrade-Insecure-Requests" = "1",
"User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
)
# The url only displayed the first 20 results of the 1,327 results, but by modifying the url to change the violations of the page results to show ‘2000’ instead. You can see and thus scrape all 1,327 results instantly without having to break it up by 63 pages.
# “show=2000&p_violations_exist=both”
# Define the URL
url <- "https://www.osha.gov/ords/imis/establishment.search?establishment=&state=AR&officetype=all&office=627100&sitezip=100000&startmonth=06&startday=03&startyear=2019&endmonth=06&endday=03&endyear=2024&p_case=all&p_start=160&p_finish=180&p_sort=12&p_desc=DESC&p_direction=Prev&p_show=2000&p_violations_exist=both"
# Make the GET request with headers
response <- GET(url, add_headers(.headers = headers))
# Check the status code
if (status_code(response) == 200) {
# If the request is successful, parse the HTML content
content <- content(response, as = "text")
webpage <- read_html(content)
# Extract all tables
tables <- webpage %>%
html_nodes("table") %>%
html_table(fill = TRUE)
# Then, because the scraper was only looking for the first table, I had to change the code to find the second table that had all of the relevant data, after inspecting the html code.
# Check if there are at least two tables
if (length(tables) >= 2) {
# Print the second table
cleaned_table <- tables[[2]]
print(tables[[2]])
} else {
print("Less than two tables found on the page.")
}
} else {
print("Failed to fetch the page.")
}
#rsw comment_fix your names:
cleaned_table <- cleaned_table %>%
clean_names()
write.csv(cleaned_table,"osha_table.csv")
colnames(cleaned_table)
View(cleaned_table)
# relevant_osha <- cleaned_table %>%
#   select(`Date Opened`,NAICS, `Establishment Name`, Type)
#rsw comment - I fixed your names
relevant_osha <- cleaned_table %>%
select(date_opened, naics, establishment_name, type) %>%
mutate(naics1 = as.character(naics))
# cleaning up the date
library(lubridate)
library(readxl)
# gfg_data=read_excel(Users/rachellsanchez/Desktop/DJNF_Merrill/2022-NAICS-Codes-listed-numerically-2-Digit-through-6-Digit.xlsx)
#rsw fixed:
naics=read_excel("NAICS_codes.xlsx") %>%
clean_names() %>%
rename(naics1 = x2022_naics_us_code, industry = x2022_naics_us_title)
setwd("~/Desktop/DJNF_Merrill/OSHA Project")
library(readxl)
# gfg_data=read_excel(Users/rachellsanchez/Desktop/DJNF_Merrill/2022-NAICS-Codes-listed-numerically-2-Digit-through-6-Digit.xlsx)
#rsw fixed:
naics=read_excel("NAICS_codes.xlsx") %>%
clean_names() %>%
rename(naics1 = x2022_naics_us_code, industry = x2022_naics_us_title)
getwd()
naics <- read_excel("NAICS_codes.xlsx")
#rsw fixed:
naics <- read_excel("/Users/rachellsanchez/Desktop/DJNF_Merrill/OSHA Project/NAICS_codes.xlsx")
naics %>%
clean_names() %>%
rename(naics1 = x2022_naics_us_code, industry = x2022_naics_us_title)
# finding which industries have the most inspections
joined_table <- relevant_osha %>%
inner_join(naics, by=c("naics1"="naics1"))
glimpse(cleaned_table)
glimpse(relevant_osha)
naics <- read_excel("/Users/rachellsanchez/Desktop/DJNF_Merrill/OSHA Project/NAICS_codes.xlsx")
clean_names() %>%
rename(naics1 = x2022_naics_us_code, industry = x2022_naics_us_title)
naics <- read_excel("/Users/rachellsanchez/Desktop/DJNF_Merrill/OSHA Project/NAICS_codes.xlsx") %>%
clean_names() %>%
rename(naics1 = x2022_naics_us_code, industry = x2022_naics_us_title)
# finding which industries have the most inspections
joined_table <- relevant_osha %>%
inner_join(naics, by=c("naics1"="naics1"))
View(joined_table)
joined_table %>%
count(industry) %>%
arrange(desc(n))
#industries with the most osha entries
# Roofing Contractors
# Framing Contractors
# Commercial and Institutional Building Construction
# Poultry Processing
# Water and Sewer Line and Related Structures Construction
# Masonry Contractors
# Temporary Help Services
# Sawmills
# Electrical Contractors and Other Wiring Installation Contractors
